# ⚙️ MLOps — Machine Learning Operations

This section includes foundational and cutting-edge papers that explore the practices, tools, and systems behind deploying, monitoring, and managing ML models at scale.

- **[Hidden Technical Debt in Machine Learning Systems](https://papers.nips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)** — Sculley et al., 2015. _Seminal paper outlining the complexity and maintainability issues in real-world ML systems._
- **[Machine Learning Operations (MLOps): Overview, Definition, and Architecture](https://arxiv.org/abs/2205.02302)** — Treveil et al., 2022. _Provides a comprehensive definition and taxonomy of MLOps components._
- **[Continuous Delivery for Machine Learning](https://martinfowler.com/articles/cd4ml.html)** — Sato et al., 2019. _Explains how CD practices can be adapted to ML workflows._
- **[TensorFlow Extended: Machine Learning Platform for Production](https://arxiv.org/abs/1708.08539)** — Baylor et al., 2017. _Introduces TFX and its architecture for production-grade ML pipelines._
- **[Data Cascades in High-Stakes AI](https://arxiv.org/abs/2109.12217)** — Sambasivan et al., 2021. _Analyzes how issues in data collection and maintenance lead to failures in deployed ML systems._
- **[ML Metadata: A System for Logging and Querying Metadata in ML Pipelines](https://arxiv.org/abs/2003.10593)** — Polyzotis et al., 2020. _Presents a metadata management system to support reproducibility and governance._
- **[Monitoring and Explainability of Models in Production](https://arxiv.org/abs/2301.10603)** — Monteiro et al., 2023. _Modern approaches to monitor drift, performance, and explainability of ML models post-deployment._
- **[MLOps: Continuous Delivery and Automation Pipelines in Machine Learning](https://arxiv.org/abs/2006.04065)** — Kreuzberger et al., 2020. _Surveys MLOps lifecycle and proposes pipeline architecture._

